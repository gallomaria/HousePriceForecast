{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2fbeb61-ff74-4236-9bfd-5b8566a97346",
   "metadata": {},
   "source": [
    "# House Prices Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b1fed4-7ce0-4aac-9676-05c4b9164310",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0331682-eefe-4772-a1cb-7fce0bff11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "import missingno as msno\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras import Sequential, optimizers, metrics\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bda98b6-02c4-44bb-9a28-adc1fa1b0a2c",
   "metadata": {},
   "source": [
    "### Read the data that will be used to select the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfbf938a-5c01-4af8-be02-3aff3e5574d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\maria\\\\Desktop\\\\PROJECTS\\\\house_prices_forecast\\\\train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import the data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\maria\\\\Desktop\\\\PROJECTS\\\\house_prices_forecast\\\\train.csv'"
     ]
    }
   ],
   "source": [
    "# Import the data\n",
    "folder = os.getcwd()\n",
    "df = pd.read_csv(os.path.join(folder, \"train.csv\"))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e91ac16-8d4e-4f25-9683-56ffd33054f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf870f-8f73-487b-8c1c-9b03b907129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d41072-92a0-4205-bdd3-c3a72b91e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2bc7c-6114-4015-8d9c-f4e94c907078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[df.isnull().any()]].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c11e55-b0b5-4709-9a04-3119bbb3ec2f",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7ee9c-b173-466c-9cdb-8d0aed380d2b",
   "metadata": {},
   "source": [
    "Anaysis of the missing data pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a0b321-4f35-42e1-9ed0-1b8e4ac9185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb02cfc4-b73d-4f6d-818c-dbf1fa763069",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed58ebb7-1ba4-4437-b743-39653e68f65d",
   "metadata": {},
   "source": [
    "Imputation of the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c035f6e5-117e-4750-bb13-e3f44f4eb48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LotFrontage: Linear feet of street connected to property\n",
    "print(df[\"LotFrontage\"].isna().sum() / df.shape[0] * 100)\n",
    "# assumption: NAs == no street connected to property\n",
    "df[\"LotFrontage\"] = df[\"LotFrontage\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5ef8a-78cc-41a4-91bc-d2a46852a79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alley: Type of alley access\n",
    "print(df[\"Alley\"].isna().sum() / df.shape[0] * 100)\n",
    "print(df[\"Alley\"].unique())\n",
    "# 93.77% of Nas -> rm NAs\n",
    "df = df.drop(columns=\"Alley\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8343449-ece1-406a-95db-0d66a1f78463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MasVnrType: Masonry veneer type\n",
    "print(df[\"MasVnrType\"].isna().sum() / df.shape[0] * 100)\n",
    "print(df[\"MasVnrType\"].unique())\n",
    "# use a place holder\n",
    "df[\"MasVnrType\"] = df[\"MasVnrType\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc7ee1-1b87-4115-ab86-29c4478511c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MasVnrArea: Masonry veneer type\n",
    "print(df[\"MasVnrArea\"].isna().sum() / df.shape[0] * 100)\n",
    "# assumption: NAs == no Masonry veneer\n",
    "df[\"MasVnrArea\"] = df[\"MasVnrArea\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930fe33a-810d-462f-9bd9-3028dd0d6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bsmt\n",
    "print(df[\"BsmtQual\"].isna().sum() / df.shape[0] * 100)\n",
    "print(df[\"BsmtQual\"].unique())\n",
    "# use a place holder\n",
    "df[\"BsmtQual\"] = df[\"BsmtQual\"].fillna(\"Unknown\")\n",
    "df[\"BsmtCond\"] = df[\"BsmtCond\"].fillna(\"Unknown\")\n",
    "df[\"BsmtExposure\"] = df[\"BsmtExposure\"].fillna(\"Unknown\")\n",
    "df[\"BsmtFinType1\"] = df[\"BsmtFinType1\"].fillna(\"Unknown\")\n",
    "df[\"BsmtFinType2\"] = df[\"BsmtFinType2\"].fillna(\"Unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf5bb39-9a09-42ce-9809-ca3f581285e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electrical\n",
    "print(df[\"Electrical\"].isna().sum() / df.shape[0] * 100)\n",
    "print(df[\"Electrical\"].unique())\n",
    "# use a place holder\n",
    "df[\"Electrical\"] = df[\"Electrical\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204a050-8648-426a-9a04-26af3e0abc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FireplaceQu\n",
    "print(df[\"FireplaceQu\"].isna().sum() / df.shape[0] * 100)\n",
    "print(df[\"FireplaceQu\"].unique())\n",
    "# use a place holder\n",
    "df[\"FireplaceQu\"] = df[\"FireplaceQu\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c41b275-3084-4b9f-883a-caea249ecd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garage\n",
    "print(df[\"GarageType\"].isna().sum() / df.shape[0] * 100)\n",
    "print(df[\"GarageType\"].unique())\n",
    "# use a place holder\n",
    "df[\"GarageType\"] = df[\"GarageType\"].fillna(\"NoGarage\")\n",
    "df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"].fillna(9999)\n",
    "df[\"GarageFinish\"] = df[\"GarageFinish\"].fillna(\"NoGarage\")\n",
    "df[\"GarageQual\"] = df[\"GarageQual\"].fillna(\"NoGarage\")\n",
    "df[\"GarageCond\"] = df[\"GarageCond\"].fillna(\"NoGarage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746c831-d8d6-49c7-b1b7-8d68c3428d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoolQC\n",
    "print(df[\"PoolQC\"].isna().sum() / df.shape[0] * 100)\n",
    "print(df[\"PoolQC\"].unique())\n",
    "# use a place holder\n",
    "df[\"PoolQC\"] = df[\"PoolQC\"].fillna(\"NoPool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819fdda7-bcb8-45e8-a536-7834f50703e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fence\n",
    "print(df[\"Fence\"].isna().sum() / df.shape[0] * 100)\n",
    "print(df[\"Fence\"].unique())\n",
    "# use a place holder\n",
    "df[\"Fence\"] = df[\"Fence\"].fillna(\"NoFence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f7c8a5-9a70-420c-ae39-ba0936262b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiscFeature\n",
    "print(df[\"MiscFeature\"].isna().sum() / df.shape[0] * 100)\n",
    "print(df[\"MiscFeature\"].unique())\n",
    "# use a place holder\n",
    "df[\"MiscFeature\"] = df[\"MiscFeature\"].fillna(\"NoMiscFeature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729c48b0-701a-4ef7-b0f6-3779159b604d",
   "metadata": {},
   "source": [
    "### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255e1d87-8b95-4126-a4eb-1613b1c37feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empiric distribution of the response variable\n",
    "sns.kdeplot(df[\"SalePrice\"], color=\"lightblue\", fill=True, alpha=0.5)\n",
    "plt.xlabel(\"SalePrice\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ae517-b58f-4398-a9e2-7e1b2b76c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the correlation matrix for quantitative variables\n",
    "numeric_df = df.select_dtypes(include=[\"int64\", \"float64\"])\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=False,\n",
    "    cmap=\"coolwarm\",\n",
    "    fmt=\".2f\",\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    ")\n",
    "plt.title(\"Correlation Matrix Heatmap\", fontsize=20)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e6c9e-d92e-429c-aa89-d2809106ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of Cramer's V for qualitative variables\n",
    "nominal_df = df.select_dtypes(include=[\"object\"])\n",
    "nominal_df\n",
    "\n",
    "# Function to calculate Cramér's V\n",
    "def cramers_v(confusion_matrix):\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt(phi2 / min(k - 1, r - 1))\n",
    "\n",
    "\n",
    "vcramer_matrix = pd.DataFrame(\n",
    "    index=nominal_df.columns, columns=nominal_df.columns\n",
    ")\n",
    "\n",
    "for var1 in nominal_df.columns:\n",
    "    for var2 in nominal_df.columns:\n",
    "        if var1 == var2:\n",
    "            vcramer_matrix.loc[var1, var2] = 1  \n",
    "        else:\n",
    "            confusion_matrix = pd.crosstab(df[var1], df[var2])\n",
    "            vcramer_matrix.loc[var1, var2] = cramers_v(confusion_matrix)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    vcramer_matrix.astype(float),\n",
    "    annot=False,\n",
    "    cmap=\"coolwarm\",\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    ")\n",
    "plt.title(\"Cramér's V Heatmap\", fontsize=16)\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=10)\n",
    "plt.yticks(rotation=0, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bb0122-095a-432f-aac6-89547ef268aa",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a139090-4678-4ce2-a99b-e5f7b577189c",
   "metadata": {},
   "source": [
    "Data preparation for the Modelling Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d81cf3-c10e-43e3-898a-be4f1f967a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lable encoding\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for var in nominal_df.columns:\n",
    "    df[var] = label_encoder.fit_transform(df[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0156ae-fbc0-4ab4-9c47-9e8cddc3091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing df split\n",
    "X_df = df.drop(columns='SalePrice')\n",
    "y_df = df['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.25, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ba9bb-023e-442f-96ae-763372f63740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing df without multicollinear variables \n",
    "high_corr_vars = np.where(np.abs(correlation_matrix) > 0.8)\n",
    "high_corr_pairs = [(correlation_matrix.index[x], correlation_matrix.columns[y]) for x, y in zip(*high_corr_vars) if x != y and x < y]\n",
    "\n",
    "high_cramers_v_vars = np.where(np.abs(vcramer_matrix) > 0.8)\n",
    "high_cramers_pairs = [(vcramer_matrix.index[x], vcramer_matrix.columns[y]) for x, y in zip(*high_cramers_v_vars) if x != y and x < y]\n",
    "\n",
    "X_train_red = X_train.drop(columns = ['GarageYrBlt', '1stFlrSF', 'TotRmsAbvGrd', 'GarageArea'])\n",
    "X_test_red = X_test.drop(columns = ['GarageYrBlt', '1stFlrSF', 'TotRmsAbvGrd', 'GarageArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570e1d9-f450-4636-9855-d0d030e77898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_red_scaled = scaler.fit_transform(X_train_red)\n",
    "X_test_red_scaled = scaler.transform(X_test_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2560b197-2448-401e-bcc8-c7bb670ca637",
   "metadata": {},
   "source": [
    "Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d517ce5-17bb-4dc0-8343-037f8ffc706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train_red, y_train)\n",
    "y_pred_lm = lm.predict(X_test_red)\n",
    "rmse_lm = np.sqrt(mean_squared_error(np.log(y_test + 1), np.log(y_pred_lm*1)))\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results = pd.concat([results, pd.DataFrame({'Model': ['LM'], 'RMSE': [rmse_lm]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9212348-8f15-48b3-af16-a30cf4022d83",
   "metadata": {},
   "source": [
    "Ridge with 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f48639-a154-4624-b9c7-e79a12cfe5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_ridge = {\n",
    "    'alpha': np.logspace(-3, 3, 7)  # Values from 0.001 to 1000\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(Ridge(), param_grid_ridge, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_red_scaled, y_train)\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "ridge_model = Ridge(alpha = best_alpha)\n",
    "ridge_model.fit(X_train_red_scaled, y_train)\n",
    "y_pred_ridge = ridge_model.predict(X_test_red_scaled)\n",
    "rmse_ridge = np.sqrt(mean_squared_error(np.log(y_test + 1), np.log(y_pred_ridge*1)))\n",
    "results = pd.concat([results, pd.DataFrame({'Model': ['Ridge'], 'RMSE': [rmse_ridge]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f502d-7d41-42ab-9ed3-7f7b329ae1da",
   "metadata": {},
   "source": [
    "Lasso with 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a9263f-6432-4d82-849e-99b6e8cdb3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lasso = {\n",
    "    'alpha': np.logspace(-3, 3, 7)  # Values from 0.001 to 1000\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(Lasso(max_iter=10000), param_grid_lasso, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_red_scaled, y_train)\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "lasso_model = Lasso(alpha = best_alpha, max_iter=10000)\n",
    "lasso_model.fit(X_train_red_scaled, y_train)\n",
    "y_pred_lasso = lasso_model.predict(X_test_red_scaled)\n",
    "rmse_lasso = np.sqrt(mean_squared_error(np.log(y_test + 1), np.log(y_pred_lasso*1)))\n",
    "results = pd.concat([results, pd.DataFrame({'Model': ['Lasso'], 'RMSE': [rmse_lasso]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e99e51-7a8a-4679-95fa-e56003e18060",
   "metadata": {},
   "source": [
    "Random Forest with 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da09f7f3-f613-4cf3-bba3-a518a3f26616",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],        \n",
    "    'max_depth': [None, 10, 20, 30],      \n",
    "    'min_samples_split': [2, 5, 10],       \n",
    "    'min_samples_leaf': [1, 2, 4]       \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=125, warm_start=True), param_grid=param_grid_rf, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "rf_model = RandomForestRegressor(**best_params, random_state=125)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "rmse_rf = np.sqrt(mean_squared_error(np.log(y_test + 1), np.log(y_pred_rf*1)))\n",
    "results = pd.concat([results, pd.DataFrame({'Model': ['Random Forest'], 'RMSE': [rmse_rf]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe6db3-4a12-45bf-9387-92bb85adbe4b",
   "metadata": {},
   "source": [
    "Gradient Boosting with 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351bb2ed-5d10-4fb8-9701-3adbce8b65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200, 300],        \n",
    "    'learning_rate': [0.01, 0.05, 0.1],     \n",
    "    'max_depth': [3, 4, 5],                 \n",
    "    'min_samples_split': [2, 5, 10],        \n",
    "    'subsample': [0.8, 1.0, 1.5]         \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingRegressor(random_state=65), param_grid=param_grid_gb, cv=5, scoring='neg_mean_squared_error', \n",
    "                           verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "gbm_model = GradientBoostingRegressor(**best_params, random_state=65)\n",
    "gbm_model.fit(X_train_scaled, y_train)\n",
    "y_pred_gbm= gbm_model.predict(X_test_scaled)\n",
    "rmse_gbm = np.sqrt(mean_squared_error(np.log(y_test + 1), np.log(y_pred_gbm*1)))\n",
    "results = pd.concat([results, pd.DataFrame({'Model': ['Gradient Boosting Machines'], 'RMSE': [rmse_gbm]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83b3bc-3796-4f40-a3c0-dd02640dfdc5",
   "metadata": {},
   "source": [
    "Artificial Neural Network with 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1d95c6-68a3-43e5-b584-93c77e822fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def create_model(activation,learn_rate,dropout_rate,neurons):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train_scaled.shape[1],)) )  \n",
    "    model.add(Dense(neurons, activation=activation))   \n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                optimizer=optimizers.Adam(learning_rate=learn_rate),\n",
    "                metrics=[metrics.RootMeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define the parameters grid\n",
    "activation =  ['relu','selu', 'elu', 'linear', 'tanh']\n",
    "learn_rate = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3]\n",
    "neurons = [1, 5, 10, 20]\n",
    "epochs = [10, 20, 100, 200, 300]\n",
    "batch_size = [50, 100, 500, 1000]\n",
    "\n",
    "param_grid_ann = dict(activation=activation, \n",
    "    learn_rate=learn_rate, \n",
    "    dropout_rate=dropout_rate,\n",
    "    neurons=neurons, \n",
    "    epochs=epochs, \n",
    "    batch_size=batch_size)\n",
    "\n",
    "ann_model = KerasRegressor(model=create_model, \n",
    "    neurons=neurons, \n",
    "    learn_rate=learn_rate, \n",
    "    dropout_rate=dropout_rate,\n",
    "    activation=activation)\n",
    "\n",
    "opt = RandomizedSearchCV(\n",
    "    ann_model,\n",
    "    param_distributions=param_grid_ann,\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=27),\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_iter=150,\n",
    "    random_state=123,\n",
    "    n_jobs=-1\n",
    ")\n",
    "  \n",
    "best_model = opt.fit(X_train_scaled, y_train).best_estimator_\n",
    "y_pred_ann = best_model.predict(X_test_scaled)\n",
    "rmse_ann = np.sqrt(mean_squared_error(np.log(y_test + 1), np.log(y_pred_ann*1)))\n",
    "results = pd.concat([results, pd.DataFrame({'Model': ['ANN'], 'RMSE': [rmse_ann]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d5e6ec-3093-4cea-90e1-9e2b3518306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61a81d7-b056-4e8e-bff2-9b0638c94940",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b1654-fef1-4438-9e48-1e477327b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = pd.read_csv(os.path.join(folder, \"test.csv\"))\n",
    "to_predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
